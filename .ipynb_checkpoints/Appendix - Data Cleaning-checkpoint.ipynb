{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2346fb9",
   "metadata": {},
   "source": [
    "## Data Cleaning (Appendix, Draft)\n",
    "\n",
    "Project FeederWatch is a citizen-science-based data source supported by the Cornell Lab of Ornithology, which collects observations of bird species at backyard feeders and habitats all over the world in an annual November-April survey.\n",
    "\n",
    "Our raw file comes from the [Project FeederWatch](https://feederwatch.org/explore/raw-dataset-requests/) 2021 New York checklist data and site description data. This file is extremely large and has sightings from about November 2020 to April 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68269300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688d363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sql\n",
    "%load_ext sql\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69611532",
   "metadata": {},
   "source": [
    "## Joining Original Dataset (not zero-filled) with Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f24ce9",
   "metadata": {},
   "source": [
    "Our first dataset joins the original dataset of 2021 Season Feederwatch Observations with the sites dataset with location information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e207df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in original dataset from Feederwatch for observations\n",
    "total_df = pd.read_csv(\"PFW_2021_public.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ae56c",
   "metadata": {},
   "source": [
    "We chose to drop several columns in the observations dataset (`total_df`) such that only `loc_id`, `subnational1_code`, and `species_code` are present. We also chose to eliminate most columns from the sites dataset (`sites_df`) so that only `loc_id` and `housing_density` remain, allowing for an efficient data join. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e95db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>subnational1_code</th>\n",
       "      <th>species_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L12782033</td>\n",
       "      <td>CA-ON</td>\n",
       "      <td>amtspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L12782033</td>\n",
       "      <td>CA-ON</td>\n",
       "      <td>blujay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L12782033</td>\n",
       "      <td>CA-ON</td>\n",
       "      <td>bkcchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L12755941</td>\n",
       "      <td>CA-SK</td>\n",
       "      <td>dowwoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L12755941</td>\n",
       "      <td>CA-SK</td>\n",
       "      <td>whbnut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc_id subnational1_code species_code\n",
       "0  L12782033             CA-ON       amtspa\n",
       "1  L12782033             CA-ON       blujay\n",
       "2  L12782033             CA-ON       bkcchi\n",
       "3  L12755941             CA-SK       dowwoo\n",
       "4  L12755941             CA-SK       whbnut"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns\n",
    "total_df = total_df.drop(['latitude', 'longitude',\n",
    "       'entry_technique', 'sub_id', 'obs_id', 'Month', 'Day', 'Year',\n",
    "       'PROJ_PERIOD_ID', 'how_many', 'valid', 'reviewed',\n",
    "       'day1_am', 'day1_pm', 'day2_am', 'day2_pm', 'effort_hrs_atleast',\n",
    "       'snow_dep_atleast', 'Data_Entry_Method'], axis = 1)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2696b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>housing_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L100016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L100016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L100016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L100016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L100016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc_id  housing_density\n",
       "0  L100016              2.0\n",
       "1  L100016              2.0\n",
       "2  L100016              2.0\n",
       "3  L100016              2.0\n",
       "4  L100016              2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in original dataset from Feederwatch for locations\n",
    "sites_df_all = pd.read_csv(\"PFW_count_site_data_public_2021.csv\")\n",
    "\n",
    "sites_df = sites_df_all.drop(['proj_period_id', 'yard_type_pavement', 'yard_type_garden',\n",
    "       'yard_type_landsca', 'yard_type_woods', 'yard_type_desert',\n",
    "       'hab_dcid_woods', 'hab_evgr_woods', 'hab_mixed_woods', 'hab_orchard',\n",
    "       'hab_park', 'hab_water_fresh', 'hab_water_salt', 'hab_residential',\n",
    "       'hab_industrial', 'hab_agricultural', 'hab_desert_scrub',\n",
    "       'hab_young_woods', 'hab_swamp', 'hab_marsh', 'evgr_trees_atleast',\n",
    "       'evgr_shrbs_atleast', 'dcid_trees_atleast', 'dcid_shrbs_atleast',\n",
    "       'fru_trees_atleast', 'cacti_atleast', 'brsh_piles_atleast',\n",
    "       'water_srcs_atleast', 'bird_baths_atleast', 'nearby_feeders',\n",
    "       'squirrels', 'cats', 'dogs', 'humans',\n",
    "       'fed_yr_round', 'fed_in_jan', 'fed_in_feb', 'fed_in_mar', 'fed_in_apr',\n",
    "       'fed_in_may', 'fed_in_jun', 'fed_in_jul', 'fed_in_aug', 'fed_in_sep',\n",
    "       'fed_in_oct', 'fed_in_nov', 'fed_in_dec', 'numfeeders_suet',\n",
    "       'numfeeders_ground', 'numfeeders_hanging', 'numfeeders_platfrm',\n",
    "       'numfeeders_humming', 'numfeeders_water', 'numfeeders_thistle',\n",
    "       'numfeeders_fruit', 'numfeeders_hopper', 'numfeeders_tube',\n",
    "       'numfeeders_other', 'population_atleast',\n",
    "       'count_area_size_sq_m_atleast'], axis = 1)\n",
    "sites_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ea291",
   "metadata": {},
   "source": [
    "The joined dataframe `join_df` combines `total_df` and `sites_df` using an `INNER JOIN` on `loc_id`, which provides us with information about the environment in which the observation entry took place. By doing this, we lose some data entries because their location is not described in `sites_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96659136",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = total_df.set_index('loc_id').join(sites_df.set_index('loc_id'), on = \"loc_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23ce54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_density</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.252988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.252988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.205179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_density     count\n",
       "0              1.0  0.288845\n",
       "1              2.0  0.252988\n",
       "2              3.0  0.252988\n",
       "3              4.0  0.205179\n",
       "4              1.0  0.311377"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a list of all subnational1_code in the dataset \n",
    "regions_list = total_df['subnational1_code'].unique()\n",
    "\n",
    "plot_df = pd.DataFrame(columns = ['housing_density', 'count'])\n",
    "\n",
    "def plot_species_counts(state_name):\n",
    "    df = join_df[join_df['subnational1_code'] == state_name]\n",
    "    \n",
    "    x = ['Rural', 'Subrural', 'Suburban', 'Urban']\n",
    "    counts_list = []\n",
    "    \n",
    "    rural_df = df[df[\"housing_density\"] == 1.0]\n",
    "    subrural_df = df[df[\"housing_density\"] == 2.0]\n",
    "    suburban_df = df[df[\"housing_density\"] == 3.0]\n",
    "    urban_df = df[df[\"housing_density\"] == 4.0]\n",
    "    \n",
    "    if len(rural_df) > 0 and len(subrural_df) > 0 and len(suburban_df) > 0 and len(urban_df) > 0:\n",
    "        rural_count = len(rural_df['species_code'].unique())\n",
    "        subrural_count = len(subrural_df['species_code'].unique())\n",
    "        suburban_count = len(suburban_df['species_code'].unique())\n",
    "        urban_count = len(urban_df['species_code'].unique())\n",
    "\n",
    "        counts_sum = rural_count + subrural_count + suburban_count + urban_count\n",
    "\n",
    "        counts_list.append(rural_count / counts_sum)\n",
    "        counts_list.append(subrural_count / counts_sum)\n",
    "        counts_list.append(suburban_count / counts_sum)\n",
    "        counts_list.append(urban_count / counts_sum)\n",
    "\n",
    "        plot_df.loc[len(plot_df)] = [1.0, rural_count / counts_sum]\n",
    "        plot_df.loc[len(plot_df)] = [2.0, subrural_count / counts_sum]\n",
    "        plot_df.loc[len(plot_df)] = [3.0, suburban_count / counts_sum]\n",
    "        plot_df.loc[len(plot_df)] = [4.0, urban_count / counts_sum]\n",
    "    \n",
    "#         sns.scatterplot(x = x, y = counts_list)\n",
    "\n",
    "for state in regions_list:\n",
    "    plot_species_counts(state)\n",
    "    \n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510121e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_density</th>\n",
       "      <th>count</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.252988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.252988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.205179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_density     count  2.0  3.0  4.0\n",
       "0              1.0  0.288845    0    0    0\n",
       "1              2.0  0.252988    1    0    0\n",
       "2              3.0  0.252988    0    1    0\n",
       "3              4.0  0.205179    0    0    1\n",
       "4              1.0  0.311377    0    0    0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([plot_df, pd.get_dummies(plot_df['housing_density'], drop_first = True,)], axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e4c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN WHEN READY TO EXPORT\n",
    "new_df.to_csv('all_housing_density.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93facee",
   "metadata": {},
   "source": [
    "## Creating full zero-filled csv for correlation exploration in final paper\n",
    "\n",
    "We first took the original dataset `PFW_2021_public.csv` and sliced it to only include data from NY in order to cut down our dataset. Then, we used an R function provided by FeederWatch to conduct taxonomic roll-up and zero-filling, two procedures recommended by FeederWatch to limit errors. The R code used to clean is provided [here](https://engagement-center.github.io/Project-FeederWatch-Zerofilling-Taxonomic-Rollup-Public/).\n",
    "\n",
    "1. *Taxonomic roll-up*: A process of combining observations that were recorded under different species codes but would best be treated as the same species. For example, some observers may take note of subspecies, which are then recorded under different codes than the overall species when they should logically be combined.\n",
    "\n",
    "2. *Zero-filling*: adding counts of 0 for all species that were not recorded at an observation, essential for accounting for the fact that observation data is inherently presence-only.\n",
    "\n",
    "The resulting csv is `rolled_up_NY_df.csv`, which is then additionally processed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe817fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in raw provided data, zero-filled already, only data from NY\n",
    "csv = pd.read_csv(\"rolled_up_NY_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce9459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "df = pd.DataFrame(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24f027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = list(map(str.lower, df.columns))\n",
    "df.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cd549",
   "metadata": {},
   "source": [
    "We decided to drop `latitude` and `longitude`. We also dropped irrelevant columns, such as `ENTRY_TECHNIQUE` (a variable indicating method of site localization), `PROJ_PERIOD_ID` (calendar year of end of FeederWatch season), `sub_id` and `obs_id` (indentifiers for checklist or species respectively), `effort_hrs_atleast` (survey time), and `DATA_ENTRY_METHOD` (web/mobile/paper). Only valid observations were kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04e14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping irrelevant columns\n",
    "df.drop(['unnamed: 0', '...1', 'latitude', 'longitude', 'entry_technique', 'proj_period_id', 'reviewed', 'sub_id', 'obs_id',\n",
    "        'effort_hrs_atleast', 'data_entry_method'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2460f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping observations that are not valid\n",
    "df = df[df['valid'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc65b10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>subnational1_code</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>day1_am</th>\n",
       "      <th>day1_pm</th>\n",
       "      <th>day2_am</th>\n",
       "      <th>day2_pm</th>\n",
       "      <th>snow_dep_atleast</th>\n",
       "      <th>species_code</th>\n",
       "      <th>how_many</th>\n",
       "      <th>plus_code</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blujay</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id subnational1_code  month  day  year  day1_am  day1_pm  day2_am  \\\n",
       "0  L6731705             US-NY     11   14  2020        1        1        1   \n",
       "1  L6731705             US-NY     11   14  2020        1        1        1   \n",
       "2  L6731705             US-NY     11   14  2020        1        1        1   \n",
       "3  L6731705             US-NY     11   14  2020        1        1        1   \n",
       "4  L6731705             US-NY     11   14  2020        1        1        1   \n",
       "\n",
       "   day2_pm  snow_dep_atleast species_code  how_many  plus_code  valid  \n",
       "0        1               0.0       blujay         1        NaN      1  \n",
       "1        1               0.0       blujay         0        NaN      1  \n",
       "2        1               0.0       blujay         0        NaN      1  \n",
       "3        1               0.0       blujay         0        NaN      1  \n",
       "4        1               0.0       blujay         0        NaN      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986f86c",
   "metadata": {},
   "source": [
    "By convention, bird species are stored as 6-letter codes. However, this makes readability and interpretability more difficult later on. To remedy this, we can do an inner join with a taxonomy table provided by FeederWatch so we can add a column with the species full common name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffaf9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data to local variable joined_df\n"
     ]
    }
   ],
   "source": [
    "# joining common names\n",
    "species_translate_df = pd.DataFrame(pd.read_csv(\"PFW-species-translation-table.csv\"))\n",
    "%sql joined_df << SELECT loc_id, subnational1_code, month, day, year, df.species_code, how_many, valid, day1_am, day1_pm, day2_am, day2_pm, snow_dep_atleast, species_translate_df.scientific_name, species_translate_df.american_english_name AS species_name FROM df INNER JOIN species_translate_df ON df.species_code = species_translate_df.species_code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb69fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>subnational1_code</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>species_code</th>\n",
       "      <th>how_many</th>\n",
       "      <th>valid</th>\n",
       "      <th>day1_am</th>\n",
       "      <th>day1_pm</th>\n",
       "      <th>day2_am</th>\n",
       "      <th>day2_pm</th>\n",
       "      <th>snow_dep_atleast</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>blujay</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Cyanocitta cristata</td>\n",
       "      <td>Blue Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Cyanocitta cristata</td>\n",
       "      <td>Blue Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Cyanocitta cristata</td>\n",
       "      <td>Blue Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Cyanocitta cristata</td>\n",
       "      <td>Blue Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L6731705</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2020</td>\n",
       "      <td>blujay</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Cyanocitta cristata</td>\n",
       "      <td>Blue Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354787</th>\n",
       "      <td>L2404002</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>comgol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Bucephala clangula</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354788</th>\n",
       "      <td>L2404002</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>comgol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Bucephala clangula</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354789</th>\n",
       "      <td>L2404002</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>comgol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Bucephala clangula</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354790</th>\n",
       "      <td>L2404002</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>comgol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Bucephala clangula</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354791</th>\n",
       "      <td>L2404002</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>comgol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Bucephala clangula</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24354792 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loc_id subnational1_code  month  day  year species_code  how_many  \\\n",
       "0         L6731705             US-NY     11   14  2020       blujay         1   \n",
       "1         L6731705             US-NY     11   14  2020       blujay         0   \n",
       "2         L6731705             US-NY     11   14  2020       blujay         0   \n",
       "3         L6731705             US-NY     11   14  2020       blujay         0   \n",
       "4         L6731705             US-NY     11   14  2020       blujay         0   \n",
       "...            ...               ...    ...  ...   ...          ...       ...   \n",
       "24354787  L2404002             US-NY      2   10  2021       comgol         0   \n",
       "24354788  L2404002             US-NY      2   10  2021       comgol         0   \n",
       "24354789  L2404002             US-NY      2   10  2021       comgol         0   \n",
       "24354790  L2404002             US-NY      2   10  2021       comgol         0   \n",
       "24354791  L2404002             US-NY      2   10  2021       comgol         0   \n",
       "\n",
       "          valid  day1_am  day1_pm  day2_am  day2_pm  snow_dep_atleast  \\\n",
       "0             1        1        1        1        1             0.000   \n",
       "1             1        1        1        1        1             0.000   \n",
       "2             1        1        1        1        1             0.000   \n",
       "3             1        1        1        1        1             0.000   \n",
       "4             1        1        1        1        1             0.000   \n",
       "...         ...      ...      ...      ...      ...               ...   \n",
       "24354787      1        0        0        1        0             0.001   \n",
       "24354788      1        0        0        1        0             0.001   \n",
       "24354789      1        0        0        1        0             0.001   \n",
       "24354790      1        0        0        1        0             0.001   \n",
       "24354791      1        0        0        1        0             0.001   \n",
       "\n",
       "              scientific_name      species_name  \n",
       "0         Cyanocitta cristata          Blue Jay  \n",
       "1         Cyanocitta cristata          Blue Jay  \n",
       "2         Cyanocitta cristata          Blue Jay  \n",
       "3         Cyanocitta cristata          Blue Jay  \n",
       "4         Cyanocitta cristata          Blue Jay  \n",
       "...                       ...               ...  \n",
       "24354787   Bucephala clangula  Common Goldeneye  \n",
       "24354788   Bucephala clangula  Common Goldeneye  \n",
       "24354789   Bucephala clangula  Common Goldeneye  \n",
       "24354790   Bucephala clangula  Common Goldeneye  \n",
       "24354791   Bucephala clangula  Common Goldeneye  \n",
       "\n",
       "[24354792 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44a20ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/xxpjsdt533588521bftbd6qm0000gn/T/ipykernel_1723/2566963679.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  joined_df['snow_category'] = 'No_Snow'\n"
     ]
    }
   ],
   "source": [
    "# dropping rows where snow depth was null\n",
    "joined_df = joined_df.dropna(subset=['snow_dep_atleast'])\n",
    "# creating new category with string corresponding to each value in snow depth (for binning in the line plots)\n",
    "joined_df['snow_category'] = 'No_Snow'\n",
    "joined_df.loc[joined_df['snow_dep_atleast'] == 0.001, 'snow_category'] = 'Light_Snow'\n",
    "joined_df.loc[joined_df['snow_dep_atleast'] == 5.000, 'snow_category'] = '5 to 15 cm'\n",
    "joined_df.loc[joined_df['snow_dep_atleast'] == 15.001, 'snow_category'] = 'Heavy_Snow'\n",
    "snow_dummies = pd.get_dummies(joined_df['snow_category'], drop_first=True)\n",
    "joined_df = pd.concat([joined_df, snow_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a54214",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_csv('temporary_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40433273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sql zero_filled_join_df << SELECT month, day, year, joined_df.loc_id, species_code, species_name, how_many, day1_am, day1_pm, day2_am, day2_pm, snow_dep_atleast, Light_Snow, Heavy_Snow, No_Snow, proj_period_id, yard_type_pavement, yard_type_garden, yard_type_landsca, yard_type_woods, yard_type_desert,hab_dcid_woods, hab_evgr_woods, hab_mixed_woods, hab_orchard, hab_park, hab_water_fresh, hab_water_salt, hab_residential,hab_industrial, hab_agricultural, hab_desert_scrub, hab_young_woods, hab_swamp, hab_marsh, brsh_piles_atleast, water_srcs_atleast, bird_baths_atleast, nearby_feeders, squirrels, cats, dogs, humans, housing_density, population_atleast, scientific_name, species_name FROM joined_df INNER JOIN sites_df_all ON joined_df.loc_id = sites_df_all.loc_id;\n",
    "%sql zero_filled_join_df << SELECT month, day, year, joined_df.loc_id, species_code, species_name, how_many, snow_dep_atleast, Light_Snow, Heavy_Snow, No_Snow, housing_density, population_atleast, scientific_name, species_name FROM joined_df INNER JOIN sites_df_all ON joined_df.loc_id = sites_df_all.loc_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_filled_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows where housing density is null\n",
    "zero_filled_join_df = zero_filled_joined_df.dropna(subset=['housing_density'])\n",
    "# creating new category with string \n",
    "zero_filled_joined_df['housing_density_bins'] = 'rural'\n",
    "zero_filled_joined_df.loc[zero_filled_joined_df['housing_density'] == 2.0, 'housing_density_bins'] = \"rural/suburban\"\n",
    "zero_filled_joined_df.loc[zero_filled_joined_df['housing_density'] == 3.0, 'housing_density_bins'] = \"suburban\"\n",
    "zero_filled_joined_df.loc[zero_filled_joined_df['housing_density'] == 4.0, 'housing_density_bins'] = \"urban\"\n",
    "density_dummies = pd.get_dummies(zero_filled_joined_df['housing_density_bins'], drop_first=True)\n",
    "zero_filled_joined_df = pd.concat([zero_filled_joined_df, density_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999a09a",
   "metadata": {},
   "source": [
    "We also created a joined dataframe `zero_filled_join_df` that combines `df` and `sites_df` using an `INNER JOIN` on `loc_id`, which provides us with information about the environment in which the observation entry took place. By doing this, we lose about half of our `df` data entries because their location is not described in `sites_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_filled_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN WHEN READY TO EXPORT\n",
    "zero_filled_join_df.to_csv('zero_filled_join.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9622167",
   "metadata": {},
   "source": [
    "## Creating Accipiter and Junco csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980ef01",
   "metadata": {},
   "source": [
    "The Accipiter and Junco CSVs are sliced versions of `zero_filled_join_df` that only include entries with genus \"Accipiter\" or \"Junco\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ff560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the scientific name into two columns - the genus and species names\n",
    "zero_filled_join_df[['genus','species']] = zero_filled_join_df['scientific_name'].str.split(expand=True).iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_filled_join_df['genus'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc4a5c",
   "metadata": {},
   "source": [
    "We chose Accipiter and Junco since they are distinct and differing species with a high number of observations in our data. In the final paper, there is a more in-depth explaination for this choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting Accipiter genus data\n",
    "accipiter_df = zero_filled_join_df[zero_filled_join_df['genus'] == 'Accipiter']\n",
    "\n",
    "# selecting Junco genus data\n",
    "junco_df = zero_filled_join_df[zero_filled_join_df['genus'] == 'Junco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only certain columns that we need for futher analysis\n",
    "accipiter_df = accipiter_df[['loc_id', 'genus', 'species', 'how_many', 'species_name', 'housing_density', 'rural/suburban', 'suburban', 'urban', 'population_atleast']]\n",
    "junco_df = junco_df[['loc_id', 'genus', 'species', 'how_many', 'species_name', 'housing_density', 'rural/suburban', 'suburban', 'urban', 'population_atleast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN WHEN READY TO EXPORT\n",
    "# accipiter_df.to_csv('accipiter_df.csv')\n",
    "# junco_df.to_csv('junco_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
